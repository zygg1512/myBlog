# 负载均衡算法
## 轮询（Round Robin）
依次轮询服务队列的节点列表把每个请求轮流发送到每个服务器上。一般的实现公式
```bash
(当前下标 + 1) % 数据池长度
```
如下图

![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657541307183-3701e37a-b911-4ad8-b99f-7de45d1e2779.png#averageHue=%23fcfcfa&clientId=ucfeacda7-b82e-4&from=paste&height=263&id=u3fdb689a&originHeight=525&originWidth=730&originalType=binary&ratio=1&rotation=0&showTitle=false&size=224137&status=done&style=none&taskId=u9fa35b33-1c0d-4b8e-afc8-4c584bd9a8d&title=&width=365)

假设有6次请求分别是1、2、3、4、5、6，两个服务器Server1、Server2。当 请求1 经过负载均衡设备时，按照轮询的算法就是
```bash
(1 + 1) % 2 === 0
(2 + 1) % 2 === 1
(3 + 1) % 2 === 0
(4 + 1) % 2 === 1
(5 + 1) % 2 === 0
(6 + 1) % 2 === 1
```
所以最终 1、3、5 被分发到 Server1 上，而 2、4、6 会被分发到Server2 上

### 缺点
无法考虑服务器的真实情况，该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载（下图的 Server 2）。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657541712445-56990b4e-e8d7-4e2c-823b-4f180cdaa9a8.png#averageHue=%23fcfbf9&clientId=ucfeacda7-b82e-4&from=paste&height=260&id=uc758e575&originHeight=520&originWidth=753&originalType=binary&ratio=1&rotation=0&showTitle=false&size=224138&status=done&style=none&taskId=ua865e2d4-058b-4cb7-95ab-1c870f68073&title=&width=376.5)

## 加权轮询（Weighted Round Robbin）
加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。可以动态调整权重并实时同步，是一种相对比较均衡的算法。
例如下图中，服务器 1 被赋予的权值为 5，服务器 2 被赋予的权值为 1，那么 请求1、2、3、4、5 会被发送到 Server1，请求6 会被发送到 Server2
![](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657541833520-e388f196-01f5-46fa-b09c-eccee490241d.png#averageHue=%23fcfbfa&clientId=ucfeacda7-b82e-4&from=paste&height=329&id=ub629f245&originHeight=523&originWidth=745&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u49d9640a-4ac3-4c47-bf09-0aefdcf76ff&title=&width=468)

### 缺点

- 权重大的服务节点会突然负载上升
- 由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。

例如下图中，请求1、3、5 会被发送到 Server1，但是 请求1、3 很快就断开连接，此时只有 请求5 连接 Server1。请求2、4、6 被发送到 Server2，当 请求2 的连接断开后，此时只有 请求4、6 连接 Server2。该系统继续运行时，Server2 会承担过大的负载。
![](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657541833390-990c7b10-7b49-4b10-9c68-7041e100769f.png#averageHue=%23fcfbf9&clientId=ucfeacda7-b82e-4&from=paste&height=317&id=u9644b878&originHeight=557&originWidth=757&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ub7a09aa6-f008-491d-abfc-a2c5c75a7ce&title=&width=431)

## 最少连接（least Connections）
最少连接算法就是将请求发送给当前最少连接数的服务器上。
例如下图中，Server1 当前连接数最小，那么新到来的请求 6 就会被发送到 Server1 上
![](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657541833011-ca5307eb-b3d1-4617-a5c7-1721a07de720.png#averageHue=%23fdfdfc&clientId=ucfeacda7-b82e-4&from=paste&height=348&id=ue6e80901&originHeight=521&originWidth=731&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u8fd0ba63-3640-4a76-bb0b-12cc608f045&title=&width=488)

## 加权最少连接（Weighted Least Connection）
在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。
**需要实时统计连接数，需要计算权重。**

## 随机算法（Random）
把请求随机发送到服务器上。
和轮询算法类似，该算法比较适合服务器性能差不多的场景。
![](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657542572239-5c64dbf2-d5ce-4cb2-aa0f-93ee83a6ce02.png#averageHue=%23fbfbf9&clientId=ucfeacda7-b82e-4&from=paste&height=345&id=ud1d91d98&originHeight=522&originWidth=711&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u0566f35b-c32a-4df3-8bce-acb5e0ca940&title=&width=470)

## 源地址哈希法 (IP Hash)
**为了将客户端 IP 请求固定分配给一台服务器，可以让这台服务器存储状态 session；用来实现会话粘滞（Sticky Session）**
使用ip_hash的注意点：用户ip没有发生更改，并且更改不能把后台服务器直接移除，只能标记 down

### 普通 hash 算法
假如我们有三台缓存服务器编号 Server1、Server2、Server3，现在有 3000 万个key，希望可以将这些 key 均匀的缓存到三台机器上，你会想到什么方案呢？
可能首先想到的方案，是取模算法`hash(key) % N`，对 key 进行 hash 运算后取模，N是机器的数量。
key 进行 hash 后的结果对 3 取模，得到的结果一定是0、1 或者 2，正好对应服务器 Server1、Server2、Server3，存取数据直接找对应的服务器即可，简单粗暴，完全可以解决上述的问题。如下图
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657618288555-2d5a0794-f4d1-4a25-93fd-297f418695a2.png#averageHue=%23bbbbbb&clientId=u20498735-2bf9-4&from=paste&height=337&id=u98e54fa1&originHeight=674&originWidth=718&originalType=binary&ratio=1&rotation=0&showTitle=false&size=56203&status=done&style=none&taskId=u258ef10b-e250-45fd-b52c-0dc2376ebd8&title=&width=359)

#### 缺点
取模算法虽然使用简单，但对机器数量取模，在集群扩容和收缩时却有一定的局限性，因为在生产环境中根据业务量的大小，调整服务器数量是常有的事；而服务器数量N发生变化后`hash(key) % N`计算的结果也会随之变化。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657618448311-cd9eefa3-9b6c-4fa0-a707-2ac10bb52124.png#averageHue=%23c0c0c0&clientId=u20498735-2bf9-4&from=paste&height=347&id=u726339e3&originHeight=694&originWidth=804&originalType=binary&ratio=1&rotation=0&showTitle=false&size=57904&status=done&style=none&taskId=u7a2504fb-a01f-438d-8967-b34597292c6&title=&width=402)
比如：一个服务器节点挂了，计算公式从`hash(key)% 3`变成了`hash(key)% 2`，结果会发生变化，此时想要访问一个服务器，这个服务器的位置大概率会发生改变，那么之前缓存的数据也会失去作用与意义。
**大量缓存在同一时间失效，造成缓存的雪崩，进而导致整个缓存系统的不可用**，这基本上是不能接受的，为了解决优化上述情况，一致性 hash 算法应运而生~

### 一致性 hash 算法
一致性hash算法本质上也是一种取模算法，不过，不同于上面按服务器数量取模，一致性hash是对固定值2^32 取模
> IPv4的地址最多有2^32 种，所以用 2^32 可以保证每个IP地址会有唯一的映射


#### hash环
我们可以将这 2^32 个值抽象成一个圆环，圆环正上方的点代表0，顺时针排列，以此类推，1、2、3、4、5、6……直到 2^32 - 1，而这个由2的32次方个点组成的圆环统称为**hash环**
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657624137422-ecd5c640-5a77-4a56-a9c9-7f51ff01bb62.png#clientId=u20498735-2bf9-4&from=paste&height=319&id=u19ea4a15&originHeight=638&originWidth=1130&originalType=binary&ratio=1&rotation=0&showTitle=false&size=83374&status=done&style=none&taskId=ud8a4eb2c-90e7-417e-ba29-139d104a245&title=&width=565)
那么这个hash环和一致性hash算法又有什么关系？我们还是以上面的场景为例，三台缓存服务器编号node0、node1、node2，3000万个key。

#### 服务器映射到 hash 环
这个时候计算公式就是从`hash(key) % N`变成了`hash(服务器ip) % 2^32`，使用服务器IP地址进行hash计算，用哈希后的结果对 2^32 取模，结果一定是一个 0 到 2^32 - 1 之间的整数，而这个整数映射在hash环上的位置代表了一个服务器，依次将node0、node1、node2三个缓存服务器映射到hash环上。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657624152330-5693e240-d245-4334-811f-321af865a78d.png#clientId=u20498735-2bf9-4&from=paste&height=365&id=u2b671dbf&originHeight=729&originWidth=1200&originalType=binary&ratio=1&rotation=0&showTitle=false&size=93169&status=done&style=none&taskId=u8618a83a-0a7c-48d3-a378-c053d4b346d&title=&width=600)

#### 对象key映射到hash环
接着再将需要缓存的key对象也映射到hash环上，`hash(key) % 2^32`，服务器节点和要缓存的key对象都映射到了hash环，那对象key具体应该缓存到哪个服务器上呢？
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657624249149-1200f637-845d-4f10-b9aa-1131f126bdd5.png#clientId=u20498735-2bf9-4&from=paste&height=372&id=u72c692a4&originHeight=743&originWidth=1200&originalType=binary&ratio=1&rotation=0&showTitle=false&size=112814&status=done&style=none&taskId=u7fa93af9-dce7-4576-a219-8fe3511bf4b&title=&width=600)

#### 对象key映射到服务器
> **从缓存对象key的位置开始，沿顺时针方向遇到的第一个服务器，便是当前对象将要缓存到的服务器。**

因为被缓存对象与服务器hash后的值是固定的，所以，在服务器不变的条件下，对象key必定会被缓存到固定的服务器上。根据上面的规则，下图中的映射关系：
```bash
key-1 -> node-1
key-3 -> node-2
key-4 -> node-2
key-5 -> node-2
key-2 -> node-0
```
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657624315021-8ca2ae95-26ce-4e61-8634-782a87d6e112.png#clientId=u20498735-2bf9-4&from=paste&height=364&id=uadf9901c&originHeight=728&originWidth=1200&originalType=binary&ratio=1&rotation=0&showTitle=false&size=164045&status=done&style=none&taskId=u738dde67-48ae-4179-8d39-d327053c07f&title=&width=600)
如果想要访问某个key，只要使用相同的计算方式，即可得知这个key被缓存在哪个服务器上了

#### 一致性hash的优势
> 我们简单了解了一致性hash的原理，那它又是如何解决集群中添加/缩减节点导致缓存服务大面积不可用的呢？

先来看看扩容的场景，假如业务量激增，系统需要进行扩容增加一台服务器`node-4`，刚好`node-4`被映射到`node-1`和`node-2`之间，沿顺时针方向，发现原本缓存在`node-2`上的对象`key-4`、`key-5`被重新映射到了`node-4`上，而整个扩容过程中受影响的只有`node-4`和`node-1`节点之间的一小部分对象key。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657624505157-4019bd38-b26c-4062-af23-653b591ed87c.png#clientId=u20498735-2bf9-4&from=paste&height=374&id=u162c3744&originHeight=748&originWidth=1200&originalType=binary&ratio=1&rotation=0&showTitle=false&size=169315&status=done&style=none&taskId=u58401579-4886-41e9-b979-71c63abfd5f&title=&width=600)
反之，假如`node-1`节点宕机，沿顺时针方向缓存在`node-1`上的对象`key-1`被重新映射到了`node-4`上
此时受影响的数据只有`node-0`和`node-1`之间的一小部分对象key。
![](https://cdn.nlark.com/yuque/0/2022/webp/26943751/1657624548010-dada7d54-cfa1-4aea-89e6-bd0bf19c3fdf.webp#clientId=u20498735-2bf9-4&from=paste&id=u8a70e437&originHeight=716&originWidth=1200&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ua1e5ee62-ed24-4df4-8983-850f78bf40b&title=)
从上边的两种情况发现，当集群中服务器的数量发生改变时，一致性hash算只会影响少部分的对象key，保证了缓存系统整体还可以对外提供服务的。

#### 数据偏斜问题
在服务器节点数量太少的情况下，很容易因为节点分布不均匀而造成**数据倾斜**问题，如下图被缓存的对象大部分缓存在`node-4`服务器上，导致其他节点资源浪费，系统压力大部分集中在`node-4`节点上，这样的集群是非常不健康的。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657624673647-ee45897f-e087-4232-b2cf-50aa5f996c30.png#clientId=u20498735-2bf9-4&from=paste&height=370&id=u3c693931&originHeight=739&originWidth=1200&originalType=binary&ratio=1&rotation=0&showTitle=false&size=201066&status=done&style=none&taskId=ub91cc8f3-3a96-472b-8902-3c545f92529&title=&width=600)
解决数据倾斜的办法也简单，我们就要想办法让节点映射到hash环上时，相对分布均匀一点。
一致性Hash算法引入了一个**虚拟节点机制**，即对每个服务器节点计算出多个hash值，它们都会映射到hash环上。
**映射到这些虚拟节点上的对象key，最终会缓存在真实的节点上。**
**虚拟节点的hash计算方式**：对应节点的IP地址加数字编号后缀的方式，举个例子
```javascript
//  node-1节点IP为 10.24.23.227，正常计算node-1的hash值
hash(10.24.23.227#1) % 2^32

// 假设给node-1设置三个虚拟节点
// node-1#1、node-1#2、node-1#3，对它们进行hash后取模
hash(10.24.23.227#1) % 2^32
hash(10.24.23.227#2) % 2^32
hash(10.24.23.227#3) % 2^32
```

下图加入虚拟节点后，原有节点在hash环上分布的就相对均匀了，其余节点压力得到了分摊。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657624814089-d82dd4dd-6fab-41b4-8349-e29bd254f45d.png#clientId=u20498735-2bf9-4&from=paste&height=332&id=u3312b4b4&originHeight=664&originWidth=1200&originalType=binary&ratio=1&rotation=0&showTitle=false&size=183798&status=done&style=none&taskId=ue3758203-a2cf-4413-bc37-34d1fd91549&title=&width=600)
> 但需要注意一点，分配的虚拟节点个数越多，映射在hash环上才会越趋于均匀，节点太少的话很难看出效果

引入虚拟节点的同时也增加了新的问题，要做虚拟节点和真实节点间的映射，**对象key->虚拟节点->实际节点**之间的转换
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26943751/1657625152977-b401a8c8-69c7-4904-9aa7-188ff9e3dbe9.png#clientId=u60905085-b8d3-4&from=paste&height=359&id=u5fa24401&originHeight=464&originWidth=878&originalType=binary&ratio=1&rotation=0&showTitle=false&size=145347&status=done&style=none&taskId=u8869f62b-04fe-40b9-99ad-d61a5772423&title=&width=679)

#### 一致性hash的应用场景
一致性hash在分布式系统中应该是实现负载均衡的首选算法，它的实现比较灵活，既可以在客户端实现，也可以在中间件上实现，比如：

- 日常使用较多的缓存中间件memcached和redis集群
- RPC框架Dubbo用来选择服务提供者
- 分布式关系数据库分库分表：数据与节点的映射关系
- LVS负载均衡调度器

#### 一致性hash的缺点
一致性Hash算法也是有一些潜在隐患的，如果Hash环上的节点数量非常庞大或者更新频繁时，检索性能会比较低下，而且整个分布式缓存需要一个路由服务来做负载均衡，一旦路由服务挂了，整个缓存也就不可用了，还要考虑做高可用。
