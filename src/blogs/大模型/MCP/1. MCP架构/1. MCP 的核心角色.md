# MCP 架构及核心角色

Model Context Protocol (MCP) 是由 Anthropic 推出的一项开放标准，旨在彻底解决大模型（LLM）与外部数据连接的碎片化问题。

你可以把它理解为 “AI 时代的 USB 协议” —— 一种标准化的接口，让任何 AI 模型都能即插即用，连接任何数据源。

## “前 MCP 时代”的架构缺陷

在 MCP 出现之前，LLM 应用与外部数据源（例如 Slack、Google Drive、Postgres）的集成存在不可持续的问题，系统架构面临 O(M × N) 的复杂度困境。

当每一个 AI 客户端（Client）都需要单独对接每一个数据源（Source）时，会导致以下核心问题：

-   信息孤岛问题：每个数据源都需要单独的集成方案
-   开发复杂度高：为每个 AI 应用构建定制化的数据连接器
-   缺乏标准化：不同厂商的集成方案互不兼容
-   上下文丢失：AI 在不同工具间切换时难以保持上下文连续性

### “前 MCP 时代”的架构示意图

```txt
[Claude]  ----(专属适配层)----> [Postgres]
[ChatGPT] ----(专属适配层)----> [Postgres]
[IDE]     ----(专属适配层)----> [Postgres]
(每一个连线都代表一份独立的、需要维护的代码库)
```

## MCP 架构

MCP 引入了一个通用的标准协议层。现在，开发者只需要构建一次 MCP Server，它就可以被所有支持 MCP 的客户端（Claude Desktop, Zed, Cursor 等）同时使用。

### 核心角色

MCP 体系主要由 MCP Host、MCP Client、MCP Server 三个角色组成，它们各司其职。

```txt
┌─────────────────┐
│   MCP Host      │  ← AI 应用（如 Claude Desktop）
│  (协调者)        │
└────────┬────────┘
         │
         ├─── MCP Client 1 ──→ MCP Server A (数据库)
         │
         ├─── MCP Client 2 ──→ MCP Server B (文件系统)
         │
         └─── MCP Client 3 ──→ MCP Server C (API 服务)
```

### MCP Host (宿主应用)

定位：这是用户直接使用的应用程序（如 Claude Desktop App, Cursor IDE, Windsurf）。

功能：

-   负责运行 LLM（大模型）。
-   负责发现本地或远程的 Server。
-   负责安全控制（例如：当 Server 想要读取你的文件时，Host 会弹窗询问“是否允许？”）。

关键点：Host 决定了 AI 如何展示结果，以及如何将从 Server 获取的数据注入到 AI 的 Context Window（上下文窗口）中。

### MCP Client (协议客户端)

定位：虽然用户通常只看到 Host（如 Claude App），但 Client 是 Host 内部真正“干活”的组件，负责与 Server 进行点对点的技术通信。Client 负责处理连接、鉴权、以及将 Host 的高层意图转化为底层的 MCP 协议消息。

Client 的四大核心能力：

#### 协议握手与能力协商 (Handshake & Negotiation)

Client 负责启动 Server 进程（或连接远程 URL）。连接建立之初，Client 发送 initialize 请求，告知自己支持的协议版本，并询问 Server 具备哪些能力。Server 接受后响应，返回初始化结果，包含：

1.  协议版本 (protocolVersion)：双方确认使用的 MCP 版本。
2.  能力声明 (capabilities)：Server 明确告知它支持哪些特性（例如：是否支持资源订阅、是否支持工具列表动态更新、是否支持日志系统）。
3.  服务信息 (serverInfo)：Server 的名称和版本号（如`{"name": "sqlite-server", "version": "1.0.0"}`）。

握手流程如下：

1. Client 发起初始化，Client 告知 Server 自己的版本，以及自己支持哪些高级特性（`capabilities`），如：

```json
// Client -> Server 发送的请求
{
    "jsonrpc": "2.0", // JSON-RPC 协议版本，固定为 2.0
    "id": 1, // 请求 ID，用于匹配后续的响应
    "method": "initialize", // 方法名：初始化
    "params": {
        "protocolVersion": "2024-11-05", // Client 声明自己支持的 MCP 协议版本
        "capabilities": {
            // Client 自身具备的能力声明
            "roots": {
                // 表示 Client 支持 Server 访问文件系统根目录
                "listChanged": true // 支持监控文件根目录的变化
            },
            "sampling": {} // 表示支持 Server 回调 LLM
        },
        "clientInfo": {
            // Client 的元数据信息
            "name": "Claude Desktop", // 客户端名称
            "version": "1.0.0" // 客户端版本
        }
    }
}
```

1. Server 返回能力列表，确认协议版本，并在`capabilities`中列出自己提供的能力模块，如：

```json
// Server -> Client 返回的响应
{
    "jsonrpc": "2.0",
    "id": 1, // 对应 Step A 请求的 ID
    "result": {
        "protocolVersion": "2024-11-05", // 双方协商确定的协议版本
        "capabilities": {
            // Server 声明自己具备的能力
            "logging": {}, // 支持发送日志给 Client
            "prompts": { "listChanged": true }, // 支持提供 Prompt 模板，并能通知变更
            "resources": { "subscribe": true, "listChanged": true }, // 支持资源订阅（如实时日志）
            "tools": { "listChanged": true } // 支持工具调用，并能通知工具列表变更
        },
        "serverInfo": {
            // Server 的元数据信息
            "name": "sqlite-server", // 服务端名称
            "version": "0.1.0" // 服务端版本
        }
    }
}
```

1. Client 确认握手完成。Client 发送一个没有 id 的通知 (Notification)。这标志着握手结束，双方可以开始正常的 ping、list_tools 等操作。

```json
// Client -> Server 发送的通知
// 这是一个没有响应的通知消息。它告诉 Server “我已经收到了你的能力列表，现在你可以开始给我发请求了（比如发日志给控制台，或者发采样请求）”。
{
    "jsonrpc": "2.0",
    "method": "notifications/initialized" // 通知方法名：初始化完成
    // 注意：通知消息没有 "id" 字段，因为不需要 Server 回复
}
```

#### 1:1 连接生命周期管理

MCP 采用 1:1 的连接拓扑。Client 负责维护这个连接的稳定性，处理 stdio（标准输入输出）流或 SSE（Server-Sent Events）消息的序列化与反序列化。它还需要处理错误恢复，比如 Server 崩溃时的重连或报错。

#### Sampling (采样/反向调用)

通常我们认为流程是`Client -> 调用 -> Server`。但 MCP Client 支持 Server 反向请求 Client。

场景：Server 抓取了一段极其复杂的代码，它自己没有智能去分析，它可以发送`sampling/createMessage`请求给 Client，说：“Client 大哥，能否借用你的 LLM 帮我总结一下这数据，然后再发回给我？”

意义：这使得“傻瓜式”的传统工具也能利用 Host 的大模型智力。

#### Roots 定义和管理 Server 可以访问的文件系统边界或工作上下文

Client 的 Roots 能力 (Roots Capability) 是一个核心机制，用于定义和管理 Server 可以访问的文件系统边界或工作上下文。

简单来说，就是 Client 告诉 Server：“你可以访问这些特定的文件夹或资源，但不能访问其他的。”

核心概念与目的：

1. 定义边界 (Boundaries)：Roots 定义了 Server 操作的“合法范围”。通常对应于用户 IDE 中的“打开的文件夹”、“当前项目根目录”或“工作区”。
2. 上下文感知 (Context Awareness)：通过 Roots，Client 可以告知 Server 当前用户正在处理哪些项目，帮助 Server 理解上下文（例如，代码分析 Server 需要知道源代码在哪里）。
3. 安全管控 (Security Control)：这是 MCP 安全模型的重要组成部分。Server 不应该能够随意访问用户的所有文件，Roots 限制了 Server 只能读取或操作用户明确授权的目录。

交互流程如下：

1. 在连接初始化阶段，Client 需要在 initialize 请求中声明它支持 roots 能力。

```json
// Client 发送给 Server 的初始化消息片段
{
    "capabilities": {
        "roots": {
            "listChanged": true // 声明：当根目录列表发生变化时，我会通知你
        }
    }
}
```

2. Server 可以在需要时（通常是启动后）向 Client 请求当前的 Roots 列表。

```json
// 1. 请求 (Server -> Client): roots/list
// 2. 响应 (Client -> Server): 返回一组 Root 对象，通常包含 uri (文件路径) 和 name (显示名称)。
// Client 的响应示例
{
    "jsonrpc": "2.0",
    "id": 1,
    "result": {
        "roots": [
            {
                "uri": "file:///Users/username/my-project",
                "name": "My Project"
            },
            {
                "uri": "file:///Users/username/docs",
                "name": "Documentation"
            }
        ]
    }
}
```

3. 如果用户在 Client 端（比如 VS Code 或 Cursor）打开了新的文件夹或关闭了现有文件夹，Client 会发送通知给 Server。
    1. 通知 (Client -> Server)：`notifications/roots/list_changed`
    2. 动作：Server 收到通知后，通常会重新发起`roots/list`请求来更新自己的内部状态。

### MCP Server (服务端/能力提供者)

定位：这是连接具体数据源的轻量级程序。它不运行大模型，只负责“翻译”。它将外部数据（GitHub, Postgres, 本地文件）翻译成 MCP 协议定义的标准格式。

Server 提供的三大核心能力 (Primitives)：

1. Resources
2. Tools
3. Prompts

#### Resources

Resource 是 Server 向 LLM 暴露数据的主要方式。它们是纯文本或二进制数据，通过 URI 进行标识。

-   关键特性：
    -   Direct Read (直接读取)：Client 可以随时读取资源内容。
    -   Subscribe (订阅更新)：Client 可以订阅资源。当底层数据发生变化时（例如日志文件新增了一行），Server 会推送通知，Host 可以让 LLM 重新读取最新内容。
    -   Templates (URI 模板)：Server 可以定义动态资源，例如`postgres://users/{id}/profile`。
-   JSON 数据结构示例：

```json
{
    "uri": "file:///logs/app.log",
    "name": "Application Logs",
    "description": "当前的系统运行日志，包含错误和警告信息",
    "mimeType": "text/plain"
}
```

场景：用户想让 AI 知道当前的服务器日志。流程如下：

1. Client 发现：连接建立时，Client 请求`resources/list`，Server 返回资源列表（如`log://system.log`）。
2. Host 展示：Host 界面上出现一个回形针图标，用户可以从中选择 "System Logs"。
3. Client 读取：当用户把资源附加到对话框时，Client 发送`resources/read`请求。
4. Server 响应：Server 读取本地日志文件，将内容作为文本流返回。
5. LLM 消费：Host 将这些文本直接嵌入到发给 LLM 的 Prompt 中（作为背景知识）。

#### Tools

Tool 是 Server 暴露的可执行函数。这是 LLM 与外部世界互动的唯一方式（因为读取 Resource 是被动的，不改变状态）。

-   关键特性：
    -   JSON Schema 定义：Server 必须严格定义每个工具的输入参数结构（Schema），这样 LLM 才能准确生成参数。
    -   Model-Steered (模型驱动)：Host 将工具列表发给 LLM，LLM 决定在什么时候调用哪个工具。
    -   Side Effects (副作用)：工具调用通常意味着改变系统状态（如写数据库、发请求），因此通常需要用户确认。
-   JSON 数据结构示例：

```json
{
    "name": "calculate_tax",
    "description": "根据金额和地区代码计算税费",
    "inputSchema": {
        "type": "object",
        "properties": {
            "amount": { "type": "number", "description": "商品总金额" },
            "region": {
                "type": "string",
                "description": "两位数国家代码，如 US, CN"
            }
        },
        "required": ["amount", "region"]
    }
}
```

场景：AI 需要查询数据库。流程如下：

1. Client 暴露：Client 请求`tools/list`，获取所有工具定义（名称、参数 schema）。
2. Host 注入：Host 将这些工具描述（JSON Schema）告诉 LLM：“你可以使用这些工具...”。
3. LLM 决策：用户提问后，LLM 判断需要查库，于是输出一个特殊的“函数调用请求”（Function Call），比如`call: query_sql(sql="...")`。
4. Client 执行：Host 拦截这个请求，Client 将其转化为 MCP 的`tools/call`消息发给 Server。
5. Server 执行：Server 运行 SQL，返回结果。
6. 闭环：Client 拿到结果，Host 再次喂给 LLM，LLM 生成最终自然语言回答。

#### Prompts

Prompts 是 Server 定义的、可复用的交互模板。它们帮助用户快速进入特定的工作流。

-   关键特性：
    -   Context Injection (上下文注入)： 一个 Prompt 不仅仅是一段话，它还可以预先包含特定的 Resources（资源）。例如，“Debug Error” 这个 Prompt 可能自动包含`file:///logs/error.log`。
    -   UI Integration (UI 集成)： Host 通常会在界面上以“菜单”或“斜杠命令”的形式展示 Prompts。
    -   Arguments (参数)： Prompt 可以接受用户输入参数，例如`summarize_notes(date="2023-12-01")`。
-   JSON 数据结构示例：

```json
{
    "name": "review_code_changes",
    "description": "审查 Git 暂存区中的代码变更",
    "arguments": [
        {
            "name": "branch",
            "description": "要对比的分支名",
            "required": true
        }
    ]
}
```

场景： 快速启动一个标准任务（如“Git Commit 助手”）。流程如下：

1. Client 获取： Client 请求 prompts/list。
2. UI 呈现： Host 在界面上显示“斜杠命令”或“快捷菜单”（例如`/commit-helper`）。
3. 用户触发： 用户点击菜单。
4. Client 请求： Client 发送`prompts/get`，可能还会带上参数（如果是动态 Prompt）。
5. Server 填充： Server 可以在服务端动态组合上下文（比如自动读取 git diff），生成一段完善的 Prompt 文本返回。
6. Host 填充： Host 将这段 Server 生成的 Prompt 直接填入用户的输入框，等待用户按下发送键。
