# TCP粘包
## TCP数据切片和组装
### 为什么要数据切片
假设"李东"，"亚健康终结者"这两条消息在进入传输层时使用的是传输层上的 TCP 协议。将网络比喻成一个粗细为MTU的水管。

如果把消息都传入这个水管，可能会超过这个水管的最大承受范围。那么，就需要进行切片，成为一个个数据包，这样消息才能正常通过“水管”。

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/tcp数据分片.webp" width="500px" />

消息在进入传输层（TCP）时会被切片为一个个数据包。这个数据包的长度是MSS。

#### MTU 和 MSS 有什么区别
<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/MSS和MTU.webp" height="300px" />

- MTU: Maximum Transmit Unit，最大传输单元。 由网络接口层（数据链路层）提供给网络层最大一次传输数据的大小；一般 MTU=1500 Byte。 假设IP层有 <= 1500 byte 需要发送，只需要一个 IP 包就可以完成发送任务；假设 IP 层有> 1500 byte 数据需要发送，需要分片才能完成发送，分片后的 IP Header ID 相同

- MSS：Maximum Segment Size 。 TCP 提交给 IP 层最大分段大小，不包含 TCP Header 和 TCP Option，只包含 TCP Payload ，MSS 是 TCP 用来限制应用层最大的发送字节数。 假设 MTU= 1500 byte，那么 MSS = 1500- 20(IP Header) -20 (TCP Header) = 1460 byte，如果应用层有 2000 byte 发送，那么需要两个切片才可以完成发送，第一个 TCP 切片 = 1460，第二个 TCP 切片 = 540

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/四层网络.webp" width="500px" />

### TCP Nagle 分片算法
在 Nagle 算法开启的状态下，数据包在以下两个情况会被发送：
- 如果包长度达到MSS（或含有Fin包），立刻发送，否则等待下一个包到来；如果下一包到来后两个包的总长度超过MSS的话，就会进行拆分发送；
  
- 等待超时（一般为200ms），第一个包没到MSS长度，但是又迟迟等不到第二个包的到来，则立即发送。


<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/Nagle算法.webp" width="500px"/>

启动了 Nagle算法 后，分片规则如下：
- msg1 小于 mss ，此时等待200ms内来了一个 msg2 ，msg1 + msg2 > MSS，因此把 msg2 分为 msg2(1) 和 msg2(2)，msg1 + msg2(1) 包的大小为MSS。将数据发送出去。
- 剩余的 msg2(2) 也等到了 msg3， 同样 msg2(2) + msg3 > MSS，因此把 msg3 分为 msg3(1) 和 msg3(2)，msg2(2) + msg3(1) 作为一个包发送。
- 剩余的 msg3(2) 长度不足mss，同时在200ms内没有等到下一个包，等待超时，直接发送。

此时三个包虽然在图里颜色不同，但是实际场景中，他们都是一整个 01 串，如果开发者把第一个收到的 msg1 + msg2(1) 就当做是一个完整消息进行处理，就会看上去就像是两个包粘在一起，就会导致粘包问题。


## 什么是TCP粘包
TCP粘包就是指由于使用者无法正确区分消息边界导致使用时将若干数据包错误粘连。

比如在手机上键入"李东""亚健康终结者"的时候，在 TCP 中把消息分成 MSS 大小后，消息顺着网线顺利发出。

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/消息重组.webp" width="500px" />

将消息分片传到了对端手机 B 上。经过 TCP 层消息重组。变成"李东亚健康终结者"这样的字节流（stream）。

当出现粘包时，在处理字节流的时候消息从"李东"，"亚健康终结者"变成了"李东亚"，"健康终结者"。"李东"作为上一个包的内容与下一个包里的"亚"粘在了一起被错误地当成了一个数据包解析了出来

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/粘包.webp" width="300px" />

### TCP粘包怎么发生的
TCP，传输控制协议，是一种面向连接的、可靠的、基于字节流的传输层通信协议。其中跟粘包关系最大的就是**基于字节流**这个特点

字节流可以理解为一个双向的通道里流淌的数据，这个数据其实就是我们常说的二进制数据，简单来说就是一大堆 01 串。这些 01 串之间没有任何边界。

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/字节流.webp" width="300px" />

应用层传到 TCP 协议的数据，不是以消息报为单位向目的主机发送，而是以字节流的方式发送到下游。所以
- 对于发送端来说：这些数据可能被切割和组装成各种数据包
- 对于接收端来说：收到这些数据包后没有正确还原消息，因此出现粘包现象

## 怎么处理粘包
### 关掉 Nagle 算法

Nagle 算法其实是个有些年代的东西了，诞生于 1984 年。对于应用程序一次发送一字节数据的场景，如果没有 Nagle 的优化，这样的包立马就发出去了，会导致网络由于太多的包而过载。

但是今天网络环境比以前好太多，Nagle 的优化帮助就没那么大了。而且它的延迟发送，有时候还可能导致调用延时变大，比如打游戏的时候，你操作如此丝滑，但却因为 Nagle 算法延迟发送导致慢了一拍，就问你难受不难受。

**所以现在一般也会把它关掉。TCP_NODELAY = 1。**

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/关闭Nagle算法.webp" width="300px"  />

- 接受端应用层在收到 msg1 时立马就取走了，那此时 msg1 没粘包问题
- msg2 到了后，应用层在忙，没来得及取走，就呆在 TCP Recv Buffer 中了
- msg3 此时也到了，跟 msg2 和 msg3 一起放在了 TCP Recv Buffer 中
- 这时候应用层忙完了，来取数据，图里是两个颜色作区分，但实际场景中都是 01 串，此时一起取走，发现还是粘包。

因此，就算关闭 Nagle 算法，接收数据端的应用层没有及时读取 TCP Recv Buffer 中的数据，还是会发生粘包。

### 应用层处理
粘包出现的根本原因是不确定消息的边界。接收端在面对"无边无际"的二进制流的时候，根本不知道收了多少 01 才算一个消息。一不小心拿多了就说是粘包。其实粘包根本不是 TCP 的问题，是使用者对于 TCP 的理解有误导致的一个问题。

只要在发送端每次发送消息的时候给消息带上识别消息边界的信息，接收端就可以根据这些信息识别出消息的边界，从而区分出每个消息。

#### 加入特殊标志

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/特殊标志.webp" width="300px" />

可以通过特殊的标志作为头尾，比如当收到了0xfffffe或者回车符，则认为收到了新消息的头，此时继续取数据，直到收到下一个头标志0xfffffe或者尾部标记，才认为是一个完整消息。

类似的像 HTTP 协议里当使用 chunked 编码 传输时，使用若干个 chunk 组成消息，最后由一个标明长度为 0 的 chunk 结束。

**如何防止某个数据里正好有0xfffffe这个内容？**

一般除了这个标志位，发送端在发送时还会加入各种校验字段（`校验和`或者对整段完整数据进行`CRC`之后获得的数据）放在标志位后面，在接收端拿到整段数据后校验下确保它就是发送端发来的完整数据。

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/校验字段.webp" width="300px" />

#### 加入消息长度信息
这个一般配合上面的特殊标志一起使用，在收到头标志时，里面还可以带上消息长度，以此表明在这之后多少 byte 都是属于这个消息的。如果在这之后正好有符合长度的 byte，则取走，作为一个完整消息给应用层使用。

在实际场景中，HTTP 中的Content-Length就起了类似的作用，当接收端收到的消息长度小于 Content-Length 时，说明还有些消息没收到。那接收端会一直等，直到拿够了消息或超时。


## UDP 会粘包吗
**结论：不会**

跟 TCP 同为传输层的另一个协议，UDP，User Datagram Protocol。用户数据包协议，是面向无连接，不可靠的，基于**数据报文**的传输层通信协议。

基于数据报文是指无论应用层交给 UDP 多长的报文，UDP 都照样发送，即一次发送一个报文。至于如果数据包太长，需要分片，那也是IP层的事情，大不了效率低一些。

UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。而接收方在接收数据报的时候，也不会像面对 TCP 无穷无尽的二进制流那样不清楚啥时候能结束。

正因为基于数据报文和基于字节流的差异，TCP 发送端发 10 次字节流数据，而这时候接收端可以分 100 次去取数据，每次取数据的长度可以根据处理能力作调整；但 UDP 发送端发了 10 次数据报文，那接收端就要在 10 次收完，且发了多少，就取多少，确保每次都是一个完整的数据报。

### UDP报文的边界

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/UDP报文头.webp" height="200px"/>

在报头中有`16bit`用于指示 UDP 数据报文的长度，假设这个长度是 n ，以此作为数据边界。因此在接收端的应用层能清晰地将不同的数据报文区分开，从报头开始取 n 位，就是一个完整的数据报文，从而避免粘包和拆包的问题。

当然，就算没有这个位（16位 UDP 长度），因为 IP 的头部已经包含了数据的总长度信息，此时如果 IP 包（网络层）里放的数据使用的协议是 UDP（传输层），那么这个总长度其实就包含了 UDP 的头部和 UDP 的数据。IP报头如下

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/IP报文头.webp"  height="200px"/>

因为 UDP 的头部长度固定为 8 字节（ 1 字节= 8 位，8 字节= 64 位，UDP报头中中除了`数据`以外的部分），那么这样就很容易的算出 UDP 的数据的长度了。因此说 UDP 的长度信息其实是冗余的。

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/IP和UDP长度.webp" height="200px"/>

UDP Data 的长度 = IP 总长度 - IP Header 长度 - UDP Header 长度

TCP首部里是没有长度这个信息的，跟UDP类似，同样可以通过下面的公式获得当前包的TCP数据长度。

TCP Data 的长度 = IP 总长度 - IP Header 长度 - TCP Header 长度。

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/IP和TCP长度.webp" height="200px"/>

跟 UDP 不同在于，TCP 发送端在发的时候就不保证发的是一个完整的数据报，仅仅是一连串无结构的字节流，这串字节流在接收端收到时哪怕知道长度也没用，因为它很可能只是某个完整消息的一部分。

## IP 层有粘包问题吗
**结论：不会**

IP 层会对大包进行切片，过程如下：

<img src="https://github.com/zygg1512/myBlog/raw/master/images/计算机网络/IP分包.webp"  height="600px"/>

- 如果消息过长，IP层会按 MTU 长度把消息分成 N 个切片，每个切片带有自身在包里的位置（offset）和同样的IP头信息。
- 各个切片在网络中进行传输。每个数据包切片可以在不同的路由中流转，然后在最后的终点汇合后再组装。
- 在接收端收到第一个切片包时会申请一块新内存，创建IP包的数据结构，等待其他切片分包数据到位。
- 等消息全部到位后就把整个消息包给到上层（传输层）进行处理。